# Sample Data

This subproject was developed to provide data in a useful form for developing the project's API.

## Attribution

The sample data provided for this project was extracted from Open Trivia Database ([link](https://www.opentdb.com)).  This database and API serves as a foundation for the backend portion of our project.  Our project core functionality will consist of a front-end built with React (and possibly Redux for state management and other tools to be decided later) while the backend will consist of Express running on Node.js to provide API services and database to be provided by a PostgreSQL server.

## Database Hosting

The database for this project is hosted at [ElephantSQL](https://www.elephantsql.com).  The display name for the project is "KSU-SDB-Cohort1-Project2", the server name is "heffalump" and the database is named "juqhmdzx" as is the username (same as database name).

The database password was provided in a Slack conversation from today (04-29-2022), separate from our commit history for security.

## Extracting Source Data

Source data was gathered from Open Trivia Database through use of the Postman desktop application.  GET request results were limited by their API to 50 records.  A token was generated by a separate, earlier request to the API, and that token, provided with each request, ensured each set of 50 records did not overlap with records provided from earlier requests.  As a result, we were able to acquire all 4,050 verified questions from their API as of the time this data was acquired (4-28-2022).

Those questions, with their answers, are stored in the "./sample_data/source_data/" folder with filenames of "response[N].json" where "N" ranged from 1 to 81.

The JSON response consists of a ```response_code``` and ```results``` array.  The response code for each file has a value of "0" indicating the response was provided without issue.  The results array consists of up to 50 objects (each a database record) with the following elements:  ```category```, ```type```, ```difficulty```, ```question```, ```correct_answer```, and ```incorrect_answers```.  The incorrect answers itself is an array of strings, each containing a wrong answer (distractor choices).

Note that the question and answer strings contained possible HTML entities (such as apostrophes, quotation marks, etc.) that would pose problems for our database.  In an effort to clean this data, the node package, "he" was utilized to convert these html entities into string representations with the ```he.decode()``` method call.  Additionally, apostrophes tended to remain and thus a JavaScript RegEx replacement was necessary (```.replace(/'/g, '')```) using the replace method from the String object.

The code to convert the "resonse[N].json" files into database tables with data is contained in the ```index.js``` file.  This file was run with node.js as the npm script, "sample_data".  To run this from the terminal, use the command, "npm run sample_data".  This produces the SQL script, "02-seed-unnormalized.sql" that will be discussed in the next section.

## SQL Scripts

### ```01-ddl_create_import_questions.sql```

To initially bring the data into our database, the ```import_questions``` table was created.  Note that the ```incorrect_answers``` array of data are parsed into fields, ```question_answer2```, ```question_answer3```, and ```question_answer4```.  Also, additional fields for the foreign keys were created, but not populated at this time:  ```question_category_id```, ```question_type_id```, ```question_difficulty_id```.  These will be used to set foreign key values in the questions table in a later step.

### ```02-seed-unnormalized.sql```

The data from the Open Trivia Database API was converted into an ```INSERT``` statement, which is run to populate the ```import_questions``` table with this script.

### ```03-ddl_create_categories.sql```

The first of the dimension tables to be generated, ```categories``` is populated with ```DISTINCT``` values from the ```import_questions``` table.

### ```04-ddl_create_difficulties.sql```

Likewise, the ```difficulties``` table is populated with ```DISTINCT``` values from the ```import_questions``` table.

### ```05-ddl_create_question_types.sql```

The ```question_types``` table is also populated with ```DISTINCT``` values from the ```import_questions``` table.  This time, the ```question_type``` field from ```import_questions```.

### ```06-set_seed_unnormalized_FKs.sql```

With the dimension tables populated and their primary key integers established, the foreign key fields in the ```import_questions``` table were backfilled with these, now known, primary key integers.  This established the one-to-many relationships between dimension tables and the ```questions``` table that will be created in the next step.

### ```07-ddl_create_questions.sql```

With the foreign keys populated in the ```import_questions``` table, we are now ready to create and populate the ```questions``` table.  Note the foreign key constraints that are created and then populated from the ```question_category_id```, ```question_type_id```, and ```question_difficulty_id``` fields of the ```import_questions``` table.

### ```08-ddl_create_answers.sql```

To further normalize the dataset, an ```answers``` table is created and the ```question_answer1```, ```question_answer2```, ```question_answer3```, and ```question_answer4``` fields are used to populate this from the ```questions``` table.  A foreign key constraint was created on the ```answers``` table to establish a one-to-many relationship between ```questions``` and ```answers```.  Note the use of the ```flag_correct``` field to indicate which answer of those for the same ```question_id``` is the correct answer.

### ```09-ddl_cleanup.sql```

With the answers normalized out of the ```questions``` table, these answer fields are nolonger necessary in the ```questions``` table.  In fact, these are now redundant.  To remove the redundancy, these four fields are dropped from the ```questions``` table.

### ```10-ddl_create_view_questions.sql``` and ```11-ddl_create_view_answers.sql```

To establish a pattern for the useful querying of the database, two views were created:  ```view_questions``` and ```view_answers```.  Note in the ```view_questions``` view, how the questions retreived can be further filtered by ```category_id```, ```question_type_id```, and ```difficulty_id```.

## Entity-Relationship Diagram

After running all scripts discussed above, the following ER diagram is representative of the results:

![sample_data\question_bank_erd.pgerd.png](sample_data\question_bank_erd.pgerd.png)

## To Do

- After the API models, migrations and seed data are developed and stable, this file and the contents of the sample_data folder may be archived.  At that point, their usefulness should become exhausted and they will not become a part of the final project deliverable.